import requests
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import datetime
import time
import urllib3
import pandas as pd
import os
import json

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def fetch_market_12_with_fallback():
    # å¼·åˆ¶åˆ‡æ›åˆ°æª”æ¡ˆæ‰€åœ¨ç›®éŒ„ (æœ¬åœ°æ¸¬è©¦ç”¨)
    try:
        os.chdir(os.path.dirname(os.path.abspath(__file__)))
    except:
        pass
    
    # --- è¨­å®šå€åŸŸ ---
    # å„ªå…ˆè®€å–ç’°å¢ƒè®Šæ•¸ï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨ä½ æä¾›çš„é è¨­ ID
    SPREADSHEET_ID = os.getenv('SHEET_ID')
    SHEET_NAME = 'MarketData'
    HEADERS = ["æ—¥æœŸ", "å•†å“", "é–‹ç›¤åƒ¹", "æœ€é«˜åƒ¹", "æœ€ä½åƒ¹", "æ”¶ç›¤åƒ¹", "å‚™è¨»"]
    
    # 12 æª”æ¸…å–®
    TW_STOCKS = {"2330": "2330", "2317": "2317", "2308": "2308", "2454": "2454", "2881": "2881"}
    US_INDICES = {"^SOX": "^SOX", "^IXIC": "^IXIC", "^GSPC": "^S&P 500", "^DJI": "^DJI"}

    # --- A. Google Sheets é€£ç·šé‚è¼¯ (æ”¯æ´ç’°å¢ƒè®Šæ•¸) ---
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        
        # è®€å– GitHub Actions è¨­å®šçš„ Secret
        creds_json = os.getenv('GOOGLE_CREDS_JSON')
        
        if creds_json:
            # å¦‚æœåœ¨ GitHub ç’°å¢ƒï¼šå°‡å­—ä¸²è½‰å›å­—å…¸ä¸¦é€£ç·š
            creds_dict = json.loads(creds_json)
            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        else:
            # å¦‚æœåœ¨æœ¬åœ°ç’°å¢ƒï¼šè®€å–å¯¦é«”æª”æ¡ˆ
            creds = ServiceAccountCredentials.from_json_keyfile_name('creds.json', scope)
            
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(SPREADSHEET_ID)
        
        try:
            ws = sh.worksheet(SHEET_NAME)
        except gspread.exceptions.WorksheetNotFound:
            # è‹¥å·¥ä½œè¡¨ä¸å­˜åœ¨å‰‡å»ºç«‹
            ws = sh.add_worksheet(title=SHEET_NAME, rows="5000", cols=str(len(HEADERS)))
            ws.append_row(HEADERS)
            
    except Exception as e:
        print(f"âŒ Google Sheets é€£æ¥å¤±æ•—: {e}")
        return

    # --- B. æŠ“å–é‚è¼¯ ---
    now = datetime.datetime.now()
    today_str = now.strftime('%Y-%m-%d')
    exec_time_str = now.strftime('%H:%M')
    collected_rows = []

    # 1. Yahoo è²¡ç¶“ (å°è‚¡ + ç¾è‚¡)
    headers = {'User-Agent': 'Mozilla/5.0'}
    for sym, name in {**TW_STOCKS, **US_INDICES}.items():
        url = f"https://finance.yahoo.com/quote/{sym}"
        try:
            resp = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # å–å¾—æ”¶ç›¤åƒ¹ (å¤§å­—é«”)
            price_tag = soup.find('fin-streamer', {'data-field': 'regularMarketPrice'})
            if not price_tag: continue
            close_p = float(price_tag.get_text().replace(',', ''))
            
            # å–å¾—é–‹é«˜ä½ (å¾è¡¨æ ¼æŠ“)
            open_p, high_p, low_p = close_p, close_p, close_p
            rows = soup.find_all('tr')
            for r in rows:
                txt = r.get_text()
                if 'Open' in txt: open_p = float(r.find_all('td')[1].get_text().replace(',', ''))
                if 'Day\'s Range' in txt:
                    rng = r.find_all('td')[1].get_text().replace(',', '').split(' - ')
                    low_p, high_p = float(rng[0]), float(rng[1])
            
            collected_rows.append([f"{today_str}_{exec_time_str}", name, open_p, high_p, low_p, close_p, "YahooFinance"])
            print(f"âœ… æŠ“å–æˆåŠŸ: {name}")
        except Exception as e:
            print(f"âš ï¸ {name} æŠ“å–å¤±æ•—: {e}")

    # 2. å°æŒ‡æœŸ (æœŸäº¤æ‰€å‚™æ´)
    prod_name = "å°æŒ‡æœŸ"
    success = False
    for d_offset in [0, 1]:
        d_str = (now - datetime.timedelta(days=d_offset)).strftime('%Y/%m/%d')
        contract_month = now.strftime('%Y%m')
        taifex_url = f"https://www.taifex.com.tw/cht/3/futDailyMarketReport?queryDate={d_str}&MarketCode=0&commodity_id=TX"
        try:
            r = requests.get(taifex_url, verify=False, timeout=10)
            s = BeautifulSoup(r.text, 'html.parser')
            table = s.find('table', {'class': 'table_f'})
            if table:
                trs = table.find_all('tr')
                for tr in trs:
                    tds = tr.find_all('td')
                    if len(tds) > 5 and tds[0].get_text(strip=True) == 'TX' and tds[1].get_text(strip=True) == contract_month:
                        open_p = tds[2].get_text(strip=True).replace(',', '')
                        if open_p not in ['-', '', '0']:
                            note = "æœŸäº¤æ‰€å®˜æ–¹" if d_str == today_str else f"è£œä»¶({d_str})"
                            collected_rows.append([
                                f"{today_str}_{exec_time_str}", prod_name,
                                float(open_p), float(tds[3].get_text(strip=True).replace(',', '')),
                                float(tds[4].get_text(strip=True).replace(',', '')), float(tds[5].get_text(strip=True).replace(',', '')), note
                            ])
                            success = True; break
                if success: break
        except: continue
    if not success: print(f"âš ï¸ {prod_name} å˜—è©¦å…©æ—¥å‡ç„¡è³‡æ–™")

    # --- C. æ•¸æ“šå¯«å› Sheets (å»é‡ä¸¦ä¿æŒæœ€æ–°åœ¨ä¸Š) ---
    if collected_rows:
        try:
            df_new = pd.DataFrame(collected_rows, columns=HEADERS)
            all_vals = ws.get_all_values()
            
            if len(all_vals) > 1:
                df_old = pd.DataFrame(all_vals[1:], columns=HEADERS)
                # åˆä½µå¾Œå»é‡ï¼Œä»¥ã€Œæ—¥æœŸã€å’Œã€Œå•†å“ã€ç‚ºåŸºæº–ï¼Œä¿ç•™æœ€æ–°æŠ“åˆ°çš„
                df_final = pd.concat([df_new, df_old]).drop_duplicates(subset=['æ—¥æœŸ', 'å•†å“'], keep='first')
            else:
                df_final = df_new
            
            # æ’åºï¼šæ—¥æœŸè¶Šæ–°è¶Šä¸Šé¢
            df_final = df_final.sort_values(by='æ—¥æœŸ', ascending=False)
            
            # æ›´æ–°å›è©¦ç®—è¡¨
            ws.update([df_final.columns.values.tolist()] + df_final.values.tolist())
            print(f"ğŸ“Š æ•¸æ“šåŒæ­¥å®Œæˆï¼Œå…± {len(df_final)} ç­†ç´€éŒ„ã€‚")
        except Exception as e:
            print(f"âŒ å¯«å…¥ Sheets å¤±æ•—: {e}")

if __name__ == "__main__":
    fetch_market_12_with_fallback()