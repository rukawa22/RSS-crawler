import feedparser
import gspread
from google.oauth2.service_account import Credentials
import trafilatura
from datetime import datetime, timedelta
import time
import os
import json
from bs4 import BeautifulSoup

# --- è¨­å®šå€åŸŸ (å¾ GitHub Secrets è®€å–) ---
SHEET_ID = os.getenv('SHEET_ID')
SHEET_NAME = 'CryptoRss'  # æŒ‡å®šå¯«å…¥çš„åˆ†é åç¨±

# æ‚¨æŒ‡å®šçš„ç´”åŠ å¯†è²¨å¹£ä¾†æºæ¸…å–®
RSS_URLS = [
    # --- å°ç£åŠ å¯†è²¨å¹£èˆ‡å€å¡Šéˆ (ä¸­æ–‡ï¼ŒæˆåŠŸç‡æ¥µé«˜) ---
    'https://news.cnyes.com/rss/category/crypto',           # é‰…äº¨ç¶²åŠ å¯†è²¨å¹£
    'https://technews.tw/category/blockchain/feed/',        # ç§‘æŠ€æ–°å ±å€å¡Šéˆ

    # --- ç¾åœ‹ä¸»æµåŠ å¯†åª’é«” (è‹±æ–‡ï¼Œç”¢æ¥­æ¬Šå¨) ---
    'https://decrypt.co/feed',                             # Decrypt
    'https://www.theblock.co/rss.xml',                     # The Block
    'https://bitcoinmagazine.com/.rss/full/',              # Bitcoin Magazine
    'https://www.coindesk.com/arc/outboundfeeds/rss/',     # CoinDesk
    'https://www.newsbtc.com/feed/'                        # NewsBTC
]

def get_google_sheet():
    """é€£æ¥ Google Sheetsï¼Œè‹¥åˆ†é  CryptoRss ä¸å­˜åœ¨å‰‡å»ºç«‹"""
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    creds_json = os.getenv('GOOGLE_CREDS_JSON')
    
    if creds_json:
        creds = Credentials.from_service_account_info(json.loads(creds_json), scopes=scopes)
    else:
        creds = Credentials.from_service_account_file('creds.json', scopes=scopes)
    
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(SHEET_ID)
    
    # æª¢æŸ¥åˆ†é æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å°±å»ºç«‹
    try:
        worksheet = sh.worksheet(SHEET_NAME)
    except gspread.exceptions.WorksheetNotFound:
        print(f"âš ï¸ æ‰¾ä¸åˆ°åˆ†é  '{SHEET_NAME}'ï¼Œæ­£åœ¨å»ºç«‹æ–°åˆ†é ...")
        # å»ºç«‹åˆ†é ä¸¦è¨­å®šæ¬„ä½æ¨™é¡Œ
        worksheet = sh.add_worksheet(title=SHEET_NAME, rows="2000", cols="4")
        worksheet.append_row(["æ—¥æœŸæ™‚é–“", "æ¨™é¡Œ", "å…§æ–‡", "ä¾†æºç¶²å€"])
    
    # è®€å–ç¾æœ‰æ¨™é¡Œ (é¿å…é‡è¤‡æŠ“å–)ï¼Œå–æœ€è¿‘ 300 ç­†
    existing_titles = set(worksheet.col_values(2)[:300])
    return worksheet, existing_titles

def fetch_content_with_fallback(entry):
    """å˜—è©¦æŠ“å–å…¨æ–‡ï¼Œè‹¥å¤±æ•—å‰‡å›å‚³ RSS æ‘˜è¦å‚™æ¡ˆ"""
    url = getattr(entry, 'link', '')
    if not url: return "ç„¡é€£çµ"

    # 1. å˜—è©¦æŠ“å–å…¨æ–‡ (ä½¿ç”¨å½è£ç€è¦½å™¨)
    try:
        downloaded = trafilatura.fetch_url(url, user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        if downloaded:
            content = trafilatura.extract(downloaded, include_comments=False)
            if content and len(content) > 150:
                return content
    except:
        pass

    # 2. å…¨æ–‡æŠ“å–å¤±æ•—ï¼Œæ”¹æŠ“ RSS æ‘˜è¦
    summary_raw = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
    if summary_raw:
        clean_summary = BeautifulSoup(summary_raw, "html.parser").get_text().strip()
        if clean_summary:
            return f"[æ‘˜è¦å‚™æ¡ˆ] {clean_summary[:600]}"
            
    return "ç„¡æ³•è§£æå…§æ–‡èˆ‡æ‘˜è¦ (å—ç¶²ç«™ä¿è­·)"

def main():
    try:
        worksheet, existing_titles = get_google_sheet()
        print(f"âœ… æˆåŠŸé€£ç·šåˆ°è©¦ç®—è¡¨åˆ†é : {SHEET_NAME}")
    except Exception as e:
        print(f"âŒ é€£ç·šå¤±æ•—: {e}"); return

    new_data = []
    # çµ±ä¸€å°ç£æ™‚é–“ (UTC+8)
    tw_time = datetime.utcnow() + timedelta(hours=8)
    now_str = tw_time.strftime('%Y-%m-%d %H:%M:%S')

    for rss_url in RSS_URLS:
        print(f"æ­£åœ¨æƒæ: {rss_url}")
        feed = feedparser.parse(rss_url)
        
        # å€’åºè™•ç†ï¼Œç¢ºä¿æœ€æ–°çš„åœ¨æœ€ä¸Šé¢
        for entry in reversed(feed.entries):
            title = getattr(entry, 'title', 'ç„¡æ¨™é¡Œ').strip()
            
            if not title or title in existing_titles:
                continue 

            print(f"  âœ¨ ç™¼ç¾æ–°åŠ å¯†æ–°è: {title[:25]}...")
            
            # å–å¾—å…§å®¹ (å…¨æ–‡æˆ–æ‘˜è¦)
            final_content = fetch_content_with_fallback(entry)
            
            new_data.append([now_str, title, final_content, entry.link])
            time.sleep(1.2) # ç¨å¾®å¢åŠ å»¶é²ï¼Œå°åœ‹å¤–ç«™é»æ›´å‹å–„

    if new_data:
        # å°‡æ–°è³‡æ–™æ’å…¥åˆ°æ¨™é¡Œåˆ—ä¸‹æ–¹çš„ç¬¬ä¸€åˆ— (row=2)
        worksheet.insert_rows(new_data, row=2)
        print(f"ğŸš€ æˆåŠŸæ›´æ–° {len(new_data)} ç­†åŠ å¯†è²¨å¹£æ–°èï¼")
    else:
        print("ğŸ’¡ ç›®å‰ç„¡æ–°è³‡è¨Šã€‚")

if __name__ == "__main__":
    main()
