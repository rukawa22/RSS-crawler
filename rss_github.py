import feedparser
import gspread
from google.oauth2.service_account import Credentials
import trafilatura
from datetime import datetime
import time
import os
import json

# --- è¨­å®šå€åŸŸ ---
SHEET_ID = os.getenv('SHEET_ID')
SERVICE_ACCOUNT_FILE = 'creds.json'
SHEET_NAME = 'RSS'

RSS_URLS = [
    'https://news.cnyes.com/rss/category/tw_stock', #é‰…äº¨ç¶²
    'https://www.ctee.com.tw/rss/news', #å·¥å•†æ™‚å ±
    'https://tw.stock.yahoo.com/rss?category=tw-market', #Yahoo è‚¡å¸‚
    'https://technews.tw/category/component/feed/', #ç§‘æŠ€æ–°å ±
    'https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664', #CNBC
    'https://finance.yahoo.com/news/rssindex', #Yahoo Finance
    'https://news.google.com/rss/search?q=China+economy&hl=zh-TW&gl=TW&ceid=TW:zh-Hant', #Google News
    'https://www.coindesk.com/arc/outboundfeeds/rss/', #CoinDesk
    'https://cointelegraph.com/rss' #Cointelegraph
]

# --- é€™è£¡æ˜¯ä½ å•çš„ get_google_sheet å‡½å¼å€å¡Š ---
def get_google_sheet():
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    
    # âœ… é€™æ˜¯ä½ å‰›æ‰å•çš„é‚£æ®µï¼šå„ªå…ˆè®€å– GitHub è¨­å®šçš„ Secret
    creds_json = os.getenv('GOOGLE_CREDS_JSON')
    
    if creds_json:
        # å¦‚æœåœ¨ GitHub Actions é‹è¡Œï¼Œæœƒé€²åˆ°é€™è£¡
        creds_dict = json.loads(creds_json)
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
    else:
        # å¦‚æœåœ¨ä½ è‡ªå·±çš„é›»è…¦é‹è¡Œï¼Œæœƒé€²åˆ°é€™è£¡ï¼Œæ‰¾æœ¬åœ°çš„ creds.json
        creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scopes)
    
    client = gspread.authorize(creds)
    sh = client.open_by_key(SHEET_ID)
    
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        # è®€å–ç¬¬äºŒæ¬„ï¼ˆæ¨™é¡Œï¼‰ç”¨æ–¼å»é‡
        existing_titles = set(worksheet.col_values(2))
    except gspread.exceptions.WorksheetNotFound:
        # è‹¥åˆ†é ä¸å­˜åœ¨å‰‡æ–°å¢
        worksheet = sh.add_worksheet(title=SHEET_NAME, rows="5000", cols="4")
        worksheet.append_row(["æ—¥æœŸæ™‚é–“", "æ¨™é¡Œ", "å…§æ–‡", "ä¾†æºç¶²å€"])
        existing_titles = set(["æ¨™é¡Œ"])
        
    return worksheet, existing_titles
# --- å‡½å¼çµæŸ ---

def fetch_full_text(url):
    """æ“·å–å…¨æ–‡"""
    try:
        downloaded = trafilatura.fetch_url(url)
        if downloaded is None: return "ç„¡æ³•ä¸‹è¼‰"
        result = trafilatura.extract(downloaded, include_comments=False, include_tables=True)
        return result if result else "æ“·å–ä¸åˆ°æ­£æ–‡"
    except:
        return "æ“·å–éŒ¯èª¤"

def cleanup_old_data(worksheet):
    """é˜²æ­¢è©¦ç®—è¡¨çˆ†ç‚¸ï¼šè¶…é 7000 è¡Œå°±æ¸…ç†"""
    try:
        all_values = worksheet.col_values(2)
        total_rows = len(all_values)
        if total_rows > 7000:
            print(f"æ¸…ç†èˆŠè³‡æ–™ä¸­... ç›®å‰è¡Œæ•¸: {total_rows}")
            worksheet.delete_rows(7001, total_rows)
    except Exception as e:
        print(f"æ¸…ç†å¤±æ•—: {e}")

def main():
    try:
        worksheet, existing_titles = get_google_sheet()
        print(f"æˆåŠŸé€£ç·šï¼ç›®å‰å·²æœ‰ {len(existing_titles)} å‰‡èˆŠç´€éŒ„ã€‚")
    except Exception as e:
        print(f"é€£ç·šå¤±æ•—: {e}")
        return

    new_data = []

    for rss_url in RSS_URLS:
        print(f"\n[æƒæ] {rss_url}")
        feed = feedparser.parse(rss_url)
        
        # ä½¿ç”¨ reversed ç¢ºä¿æœ€æ–°é®®çš„æ–‡ç« æœ€å¾Œè¢«è™•ç†ï¼Œé…åˆ insert_rows(row=2)
        for entry in reversed(feed.entries):
            title = getattr(entry, 'title', 'ç„¡æ¨™é¡Œ').strip()
            link = getattr(entry, 'link', '')
            
            if not link or title in existing_titles:
                continue 

            dt_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            if hasattr(entry, 'published'): dt_str = entry.published
            
            print(f"  - æ–°æ–‡ç« : {title[:20]}...")
            full_content = fetch_full_text(link)
            new_data.append([dt_str, title, full_content, link])
            time.sleep(1) 

    if new_data:
        # å†æ¬¡åè½‰è®“æœ€å‰é¢çš„è³‡æ–™æ˜¯æœ€æ–°ç™¼å¸ƒçš„
        new_data.reverse()
        print(f"\næ­£åœ¨æ’å…¥ {len(new_data)} ç­†æ–°è³‡æ–™åˆ°é ‚ç«¯...")
        worksheet.insert_rows(new_data, row=2)
        cleanup_old_data(worksheet)
        print("ğŸ‰ æ›´æ–°å®Œæˆï¼")
    else:
        print("\nâœ… æ²’æœ‰ç™¼ç¾æ–°æ–‡ç« ã€‚")

if __name__ == "__main__":
    main()
